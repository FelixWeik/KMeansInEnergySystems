\chapter{Background}
\label{cha:background}
% existing methods and concepts are fully introduced
% Mathematics of the methods is correctly covered
% self-developed/chosen solution method is motivated and described fully

% Self-developed / chosen solution method is motivated and described fully
% Summarize what the paper aims to do.
% How will the following methodological concepts help to achieve the goal of the paper?
% Why exactly are these concepts chosen?
% What keywords were used to find the papers?
% What were the search results?
% How will the papers help in answering the research questions?


% Was haben sie in den Papers der Research Questions benutzt?


% Viel aus dem Paper über die Initialisierungsmethoden zitieren, da stehen viele tolle paper drin

% Was möchte ich in diesem Abschnitt vermitteln?
% - Vorstellung von K-Means:
%   - Vorstellung eines generellen Problems
%   - Funktionsweiße mit mathematischen Grundlagen
%   - Die Elbow-Methode
%   - Initialisierungsmethoden
%   - Stärken und Schwächen
%

\section{K-Means Clustering}
\label{sec:k_means_clustering}
% General definition/idea 
Organizing unlabeled data \cite{EZU-CPF} is the general problem of the clustering analysis.
The meaningful grouping of such unlabeled data is regarded as data clustering \cite{ABI-RKC}.
This allows for the identification of patterns and trends in the data, which can be used for further analysis, such as applying more advanced theories and methods.

% Introduce the general problem the algorithm tries to solve
K-means is a partitional clustering algorithm \cite{SIN-UKC}.
It is used to group a set of n data points from z dimensions into k clusters.
This means, that a single partition of the initial dataset is produced with each point being assigned to a distinct cluster \cite{SIN-UKC}.
Clusters are produced heuristically while optimizing a criterion function defined globally on all data objects or locally on the subset of the data objects \cite{ZHU-EPC}.

\subsection{Mathematical Concepts}
K-Means clustering utilizes the concept of minimizing the sum of squared distances between a datapoint and its assigned cluster center within the whole cluster \cite{HAR-KMA}
Doing this globally exists, yet it is computationally expensive \cite{LIS-GKC}.
Therefore, the algorithm seeks local optima, such that no point can be assigned to a different cluster and the result converges \cite{SEL-GCT}.
An execution of the general algorithm is shown in \autoref{subsec:general_algorithm}.

\subsection{Initialisation Methods}
\label{subsec:initialisation_methods}
Initialization methods are used to find the initial cluster centers.
There are multiple methods to do so, for example, \texttt{RANDOM} \cite{PEN-ECI}, the \texttt{Forgy Approach} \cite{AND-CAA}, the \texttt{Macqueen Approach} \cite{MCQ-MCA}, and the \texttt{Kaufman Approach} \cite{KAU-FGD}.

The \texttt{RANDOM} approach is the most commonly used method due to its simplicity while still being an effective initialization method in terms of convergence speed and robustness \cite{PEN-ECI}.
Therefore it is assumed to be the default initialization method in this thesis.

\subsection{General Algorithm}
\label{subsec:general_algorithm}
K-means can be implemented in multiple variants.
The most general implementation using the Euclidean distance is shown in the following.
\begin{enumerate}
    \item The algorithm requires an input matrix of n data points in z dimensions and the initial cluster centers as k points in z dimensions \cite{HAR-KMA}.
          The initial cluster centers are chosen according to the used initialization method as explained in \autoref{subsec:initialisation_methods}.
    \item The average of each cluster is calculated by using $C_i = \frac{1}{M} \sum_{j=1}^{M}x_j$ with $C_i$ being the average of cluster $i$, $M$ the number of points in cluster $i$, and $x_j$ the $j$-th point in cluster $i$ \cite{SYA-IKC}.
    \item Iterate over all data points assigning each point to the nearest cluster center.
          To calculate the distance, the euclidean distance $d = \sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$ is used.
    \item Steps 2 and 3 are repeated until the criterion function converges.
          The criterion function is \begin{equation}\label{eq:sse}E=\sum_{i=1}^{k} \sum_{P \in C_i}|p-m_i|\end{equation} with $E$ being the square error-sum, $p$ the point in space, and $m_i$ the average of cluster $C_i$ \cite{LIU-BDE}.
\end{enumerate}

\subsection{Finding k: The Elbow Method}
The elbow method is a heuristic to find the optimal number $k$ of clusters for a given problem.
It is calculated by plotting the square sum of errors (\autoref{eq:sse}) against the number of clusters.
The optimal number of clusters is the point where the graph's slope changes the most, which is the so-called elbow \cite{SYA-IKC}.

\subsection{Data Scaling: The MinMaxScaler}
The MinMaxScaler is a data scaling tool of the \texttt{Scikit Learn} library \cite{SKL-MMS}.
It scales given data to a range of 0 to 1, yet it keeps the shape of the original distribution.
Most of the following papers use this scaler before applying k-means clustering.
For each value $x$ in the dataset is scaled applying \begin{equation}\label{eq:minmaxscaler} 
      x_{transformed} = \frac{x - x_{min}}{x_{max} - x_{min}}
\end{equation} for each of the datapoints \cite{JOJ-ENP}.
This ensures that the different scales of the data do not influence the clustering result and therefore improves the total clustering performance \cite{GOG-WSI}.

% Weniger Detail => Was machen die Papers um zu den Findings zu kommen anstatt
%//TODO More details Energy-related research questions

% Was sollen die folgenden beiden sections vermitteln?
%  Wichtig: Vergleichen zwischen verschiedenen Methoden, aber nur bei großen Unterschieden.
%  - Grundlegende Vorstellung der Methoden der Papers
%   - Aus welcher Perspektive gehen die Paper an die jeweilige Fragestellung heran?
%   - Warum verwendet das jeweilige Paper diese Methoden (wie sinnvoll ist das im gegebenen Kontext)? 
%   - Was möchten die jeweiligen Paper erreichen?
%   - In welchem Kontext stehen die Paper (bezogen auf die research questions)?
%   - Wie wenden die Paper k-means an?
%   - Dabei nicht jede Methodik einzeln aufschlüsseln, eher zusammenfassen.
%   - Werden die Daten danach weiter verarbeitet (weiterführende Theorien, ...)?
\section{Methodology of the Research Questions}
\label{sec:methodology_of_the_research_questions}
Three papers provide findings impacting the given research questions.
Each paper has a different perspective, namely the perspective of the industry, private households, and energy load profiles of a specific country.
The following section describes the goals of each paper and how the research is conducted to achieve these goals.

"\textit{Big Data-Informed Energy Efficiency Assessment of China Industry Sectors based on K-Means Clustering}" \cite{LIU-BDE} focuses on clustering Chinese industry sectors and distinct companies into three clusters, based on environmental perfomance derived metrics.
Liu et al. apply k-means clustering on disclosed environmental performance data of 15.128 Chinese companies between 2000 and 2015.
By applying k-means clustering with a fixed value of $k=3$, the companies and industry sectors are divided into low-, mid-, and high-performing clusters according to the chosen metrics, for example, $SO_2$ emissions.

"\textit{Identifying Home System of Practices for Energy Use with K-Means Clustering}" \cite{MAL-HBP} focuses on finding home systems of practices (HSOPs) by clustering energy load profiles of 39 private households in Blacktown, Australia.
Each cluster represents a home system of practices (HSOP), a habit or behavior that alters the standard load profile.
By applying social theory and survey results distributed to the households' residents afterwards it can be derived how behaviors and habits impact electricity consumption.

"\textit{Identification of Natural Disaster Impacted Electricity Laod Profiles with k-means Clustering Algorithm}" \cite{JES-IND} investigates the load profiles of Lombok, Indonesia between 2015 and 2022.
The data is clustered in a varying number of clusters.
These clusters are then labeled as normal or abnormal, with abnormal being either natural disaster-impacted or electrical fault-impacted which means, non human induced.
This shows how k-means helps in understanding patterns, trends and the consequences of different impacts on the electricity load profiles.

All of these papers contribute to understanding general electricity load profiles and how different impacts alter the consumption data.
The results are then used to conclude how the design of energy-saving incentives can be improved.

% Was ist wichtig in diesem Absatz bzw. was unterscheidet diese Methodik von denen davor?
% - Einführung in die gesammelte Datenmenge => wir haben jetzt zwei Datensätze, auf einem wird geclustert, auf dem anderen werden die Cluster danach analysiert
% - Die Daten werden mit dem MinMaxScaler skaliert
% - Cluster werden mit den Daten zu den Naturkatastrophen gelabeled => Darauf werden dann die einzelnen Naturkatastrophen auf die Climate Resilience des Systems analysisert


% % Data collection
% First, data from 2015 to 2022 is collected and prepared.
% The data collection happens in multiple steps: First, the electricity load data and the natural disaster data are collected.
% The data on natural disasters is provided by the National Disaster Management Agency (BNPB) of Indonesia \cite{BNP-CAD}.
% The paper focuses on earthquakes since they happen the most frequently while having a significant impact on the electricity system.
% Therefore data on the time, the Richter scale severity and the epicenter location of the earthquakes is collected.

% % Data preparation (scaling the data)
% The MinMaxScaler is applied to scale the data to a range of 0 to 1.
% It preserves the shape of the original distribution so the original information is not lost \cite{GOG-WSI}.
% % For each value $x$ in the dataset is scaled applying \begin{equation}\label{eq:minmaxscaler} 
% %       x_{transformed} = \frac{x - x_{min}}{x_{max} - x_{min}}
% % \end{equation} for each of the datapoints \cite{JOJ-ENP}.
% This is done to avoid the influence of the different scales of the data on the clustering result and therefore improves the total clustering performance \cite{GOG-WSI}.
% The optimal number of clusters is found using the elbow method as explained in \autoref{sec:k_means_clustering}.

% % Seasonal Distribution Analysis
% K-Means is executed on the entire load profile duration and a year-by-year profile duration.
% It is expected to reveal general trends and characteristics as well as precise variations in the load profile.
% After clustering each daily profile will be assigned to a distinct cluster.
% % Separation into normal and abnormal load profiles
% A normal daily electricity load profile is an electricity profile that either resembles the average daily load profile of the specific year in shape and magnitude or is a product of electricity consumer behavior variations.
% An abnormal profile is defined as either experiencing few significant power consumption drops or containing low-magnitude power consumption values that are non-consumer behavior induced.

% % Cluster Labelling
% Clusters are labeled either as disturbance-impacted or normal.
% Disturbance-impacted clusters are either natural disaster-impacted or electrical fault-impacted.
% If a natural disaster does not occur simultaneously with an abnormal load profile, the profile is labeled as electrical fault-impacted.

% % Further analysis of the data regarding climate resilience capability
% After clustering, the data is further analyzed regarding climate resilience capability.
% This means, the data is analyzed in terms of robustness, resourcefulness, and recovery of the electricity system.
% This includes data on the outbreak of the disruption, the impact size, time at the bottom, and recovery duration. and the average restoration rate of the electricity system.

